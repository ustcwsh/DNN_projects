{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "        DEFINE YOUR PREFERRED FUNCTIONS HERE \n",
    "    \"\"\"\n",
    "    return np.cos(10*x)\n",
    "\n",
    "num_examples = 5000\n",
    "validation_fraction = 0.1\n",
    "test_fraction = 0.1\n",
    "\n",
    "validation_set_size = int(num_examples*validation_fraction)\n",
    "test_set_size = int(num_examples*test_fraction)\n",
    "training_set_size = num_examples - validation_set_size - test_set_size\n",
    "\n",
    "assert type(num_examples)==int and num_examples>0\n",
    "assert training_set_size>0\n",
    "\n",
    "all_x = np.random.uniform(0*np.pi, np.pi, (1, num_examples)).T\n",
    "np.random.shuffle(all_x)\n",
    "x_training, x_validation, x_test = (all_x[:training_set_size], \n",
    "                                    all_x[training_set_size: training_set_size + validation_set_size],\n",
    "                                    all_x[training_set_size + validation_set_size:])\n",
    "(y_training, y_validation, y_test) = (f(x) for x in (x_training, x_validation, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()  \n",
    "        self.fc1 = nn.Linear(1, 50)  \n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 50)\n",
    "        self.fc4 = nn.Linear(50, 50)\n",
    "        self.fc5 = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor(x_training, dtype=torch.float, requires_grad=True)\n",
    "target = torch.tensor(y_training, dtype=torch.float)\n",
    "criterion = nn.MSELoss()\n",
    "training_epoch = 1000\n",
    "epoch_digit = len(list(str(training_epoch)))\n",
    "display_step = int(training_epoch * 0.1)\n",
    "display_precision = 6\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1/4000\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, training_epoch+1): \n",
    "    optimizer.zero_grad()\n",
    "    net.zero_grad()\n",
    "    outputs = net(input)\n",
    "    loss = criterion(outputs, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss = loss.item()\n",
    "    if not epoch % display_step:    # print every display step\n",
    "        print('[%0*d] loss: %.*f' %\n",
    "                (epoch_digit, epoch, display_precision, running_loss))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = net(input)\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    plt.scatter(input.detach().numpy(), out.detach().numpy(), c='r', label='prediction on the training set', s=5)\n",
    "    plt.scatter(input.detach().numpy(), y_training, c='b', label='labels', s=5)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(x_test, dtype=torch.float)\n",
    "with torch.no_grad():\n",
    "    out = net(inputs)\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    plt.scatter(inputs.detach().numpy(), out.detach().numpy(), c='r', label='prediction on the test set', s=5)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
