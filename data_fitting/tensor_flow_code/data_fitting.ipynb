{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network(DNN) for data fitting\n",
    "### Shuhe Wang, Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.framework.python.framework import checkpoint_utils as cu\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize global parameters here.\n",
    "num_examples = 5000\n",
    "validation_fraction = 0.1\n",
    "test_fraction = 0.1\n",
    "training_epochs = 1000\n",
    "lambd  = 1.0\n",
    "PLOT_FIGURE = True\n",
    "figure_size = (8, 4.5)\n",
    "marker_size = 5.0\n",
    "neuron_of_layer = [1, 50, 50, 50, 50, 50, 50, 50, 1]\n",
    "\n",
    "# The parameters below are automatically generated\n",
    "# !!! DO NOT CHANGE !!!\n",
    "validation_set_size = int(num_examples*validation_fraction)\n",
    "test_set_size = int(num_examples*test_fraction)\n",
    "training_set_size = num_examples - validation_set_size - test_set_size\n",
    "training_epochs_digits = len(list(str(training_epochs)))\n",
    "display_step = int(training_epochs*0.1)\n",
    "num_of_all_layers = len(neuron_of_layer)\n",
    "num_of_hidden_layers = num_of_all_layers - 2\n",
    "\n",
    "assert type(num_examples)==int and num_examples>0\n",
    "assert training_set_size>0\n",
    "assert type(training_epochs)==int and training_epochs>10\n",
    "for i in neuron_of_layer:\n",
    "    assert type(i)==int and i>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "        DEFINE YOUR PREFERRED FUNCTIONS HERE\n",
    "    \"\"\"\n",
    "    return np.cos(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = np.random.uniform(0*np.pi, np.pi, (1, num_examples)).T\n",
    "np.random.shuffle(all_x)\n",
    "\n",
    "x_training, x_validation, x_test = (all_x[:training_set_size], \n",
    "                                    all_x[training_set_size: training_set_size + validation_set_size],\n",
    "                                    all_x[training_set_size + validation_set_size:])\n",
    "\n",
    "(y_training, y_validation, y_test) = (f(x) for x in (x_training, x_validation, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_FIGURE:\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    plt.scatter(x_training, y_training, c='r', label='training set', s=marker_size)\n",
    "    plt.scatter(x_validation, y_validation, c='b', label='validation set', s=marker_size)\n",
    "    plt.legend()\n",
    "    fig.savefig(os.path.join(figure_path, 'training_and_validation_sets.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"./figure\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "figure_path = os.getcwd() + '/figure'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "(X, Y) = (tf.placeholder(tf.float32, [None, neuron_of_layer[0]], name='Input'),\n",
    "          tf.placeholder(tf.float32, [None, neuron_of_layer[-1]], name='Output'))\n",
    "(weights, biases) = ({str(i): tf.Variable(tf.random_normal([neuron_of_layer[i], neuron_of_layer[i+1]]),\n",
    "                          name = 'w{:d}'.format(i)) for i in range(num_of_all_layers-1)},\n",
    "                     {str(i): tf.Variable(tf.zeros([neuron_of_layer[i+1]]), name = 'b{:d}'.format(i))\n",
    "                          for i in range(num_of_all_layers-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN(input_data, num_of_hidden_layers):\n",
    "    def _build_hidden(num_of_hidden_layers):\n",
    "        current_layer = 0\n",
    "        output_current_layer = input_data[:]\n",
    "        while current_layer < num_of_hidden_layers:\n",
    "            Z = tf.add(\n",
    "                    tf.matmul(output_current_layer, weights['%d'%(current_layer)]),\n",
    "                    biases['%d'%(current_layer)]\n",
    "                )\n",
    "            output_current_layer = tf.nn.sigmoid(Z, name='layer%d'%(current_layer))\n",
    "            current_layer += 1\n",
    "        return str(current_layer), output_current_layer \n",
    "\n",
    "    next_layer, layer = _build_hidden(num_of_hidden_layers)  \n",
    "    output_NN = tf.add(tf.matmul(layer, weights[next_layer]), biases[next_layer])\n",
    "    return output_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = DNN(X, num_of_hidden_layers)\n",
    "cost = tf.reduce_mean(tf.square(output - Y))\n",
    "loss = tf.nn.l2_loss(output - Y)\n",
    "for key in weights:\n",
    "    loss += tf.nn.l2_loss(weights[key]) * lambd/2/num_examples\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, training_epochs+1):\n",
    "    _, c = sess.run(\n",
    "        [optimizer, cost ],\n",
    "        feed_dict={X: x_training, Y: y_training}\n",
    "    )\n",
    "\n",
    "    mse = sess.run(tf.nn.l2_loss(output - y_validation), feed_dict={X: x_validation})\n",
    "    \n",
    "    if not epoch % display_step :\n",
    "        print('Epoch: %0*d\\tCost : %.6f'%(training_epochs_digits, epoch, c))\n",
    "        if PLOT_FIGURE:\n",
    "            fig = plt.figure(figsize=figure_size)\n",
    "            plt.scatter(x_validation, y_validation, color='b', label='validation set', s=marker_size)\n",
    "            plt.scatter(x_validation, sess.run(output, feed_dict={X: x_validation}),\n",
    "                        color='r', label='DNN prediction', s=marker_size) \n",
    "            plt.legend()         \n",
    "            fig.savefig(os.path.join(figure_path, '%*d_DNN_prediction.jpg'%(training_epochs_digits, epoch)))\n",
    "\n",
    "print('Epoch: %03d\\tMSE  : %.6f'%(epoch, c), 'Training complete!', sep='\\n')\n",
    "\n",
    "save_model_list = [weights[i] for i in weights] + [biases[i] for i in biases]\n",
    "saver = tf.train.Saver(save_model_list)\n",
    "saver.save(sess, './trained_model/trained_model.ckpt')\n",
    "\n",
    "plt.close('all')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your trained DNN now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def _DNN(input_data, num_of_hidden_layers):\n",
    "    def _build_hidden(num_of_hidden_layers):\n",
    "        current_layer = 0\n",
    "        output_current_layer = input_data[:]\n",
    "        while current_layer < num_of_hidden_layers:\n",
    "            Z = np.add(\n",
    "                    np.matmul(output_current_layer, _weights['%d'%(current_layer)]),\n",
    "                    _biases['%d'%(current_layer)]\n",
    "                )\n",
    "            output_current_layer = sigmoid(Z)\n",
    "            current_layer += 1\n",
    "        return str(current_layer), output_current_layer \n",
    "        \n",
    "    next_layer, layer = _build_hidden(num_of_hidden_layers)  \n",
    "    output_NN = np.add(np.matmul(layer, _weights[next_layer]), _biases[next_layer])\n",
    "    return output_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ckpt_reader = tf.train.load_checkpoint('./trained_model/')\n",
    "for model_element in cu.list_variables('./trained_model/'):\n",
    "    print(model_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_weights, _biases) = ({str(i): _ckpt_reader.get_tensor('w{:d}'.format(i)) for i in range(num_of_all_layers-1)}, \n",
    "                       {str(i): _ckpt_reader.get_tensor('b{:d}'.format(i)) for i in range(num_of_all_layers-1)})\n",
    "\n",
    "_output = _DNN(x_test, num_of_hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize = figure_size)\n",
    "plt.scatter(x_test, y_test, color='b', label='test set', s=marker_size)\n",
    "plt.scatter(x_test, _output, color='g', label='DNN prediction', s=marker_size)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
